{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eada717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that you have all these libaries available to run the code successfully\n",
    "from pandas_datareader import data\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import urllib.request, json\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf # This code has been tested with TensorFlow 1.6\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42ddc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join('Stocks','hpq.us.txt'),delimiter=',',usecols=['Date','Open','High','Low','Close'])\n",
    "    print('Loaded data from the Kaggle repository')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9d6b72",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c5d881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort DataFrame by date\n",
    "df = df.sort_values('Date')\n",
    "\n",
    "# Double check the result\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72fe973",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c102580e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (18,9))\n",
    "plt.plot(range(df.shape[0]),(df['Low']+df['High'])/2.0)\n",
    "plt.xticks(range(0,df.shape[0],500),df['Date'].loc[::500],rotation=45)\n",
    "plt.xlabel('Date',fontsize=18)\n",
    "plt.ylabel('Mid Price',fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13f1ace",
   "metadata": {},
   "source": [
    "# Splitting Data into a Training set and a Test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610c81c0",
   "metadata": {},
   "source": [
    "You will use the mid price calculated by taking the average of the highest and lowest recorded prices on a day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cf6412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First calculate the mid prices from the highest and lowest\n",
    "high_prices = df.loc[:,'High'].as_matrix()\n",
    "low_prices = df.loc[:,'Low'].as_matrix()\n",
    "mid_prices = (high_prices+low_prices)/2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed39343",
   "metadata": {},
   "source": [
    "Now you can split the training data and test data. The training data will be the first 11,000 data points of the time series and rest will be test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4671f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = mid_prices[:11000]\n",
    "test_data = mid_prices[11000:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63ecd5d",
   "metadata": {},
   "source": [
    "# Normalizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8144006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data to be between 0 and 1\n",
    "# When scaling remember! You normalize both test and train data with respect to training data\n",
    "# Because you are not supposed to have access to test data\n",
    "scaler = MinMaxScaler()\n",
    "train_data = train_data.reshape(-1,1)\n",
    "test_data = test_data.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5c0c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Scaler with training data and smooth data\n",
    "smoothing_window_size = 2500\n",
    "for di in range(0,10000,smoothing_window_size):\n",
    "    scaler.fit(train_data[di:di+smoothing_window_size,:])\n",
    "    train_data[di:di+smoothing_window_size,:] = scaler.transform(train_data[di:di+smoothing_window_size,:])\n",
    "\n",
    "# You normalize the last bit of remaining data\n",
    "scaler.fit(train_data[di+smoothing_window_size:,:])\n",
    "train_data[di+smoothing_window_size:,:] = scaler.transform(train_data[di+smoothing_window_size:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753c863c",
   "metadata": {},
   "source": [
    "Reshape the data back to the shape of [data_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87d0109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape both train and test data\n",
    "train_data = train_data.reshape(-1)\n",
    "\n",
    "# Normalize test data\n",
    "test_data = scaler.transform(test_data).reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84ad264",
   "metadata": {},
   "source": [
    "You can now smooth the data using the exponential moving average. This helps you to get rid of the inherent raggedness of the data in stock prices and produce a smoother curve.\n",
    "\n",
    "Note that you should only smooth training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a001b19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now perform exponential moving average smoothing\n",
    "# So the data will have a smoother curve than the original ragged data\n",
    "EMA = 0.0\n",
    "gamma = 0.1\n",
    "for ti in range(11000):\n",
    "  EMA = gamma*train_data[ti] + (1-gamma)*EMA\n",
    "  train_data[ti] = EMA\n",
    "\n",
    "# Used for visualization and test purposes\n",
    "all_mid_data = np.concatenate([train_data,test_data],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69897aeb",
   "metadata": {},
   "source": [
    "# Prediction based on Standard Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c41321a",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 100\n",
    "N = train_data.size\n",
    "std_avg_predictions = []\n",
    "std_avg_x = []\n",
    "mse_errors = []\n",
    "\n",
    "for pred_idx in range(window_size,N):\n",
    "\n",
    "    if pred_idx >= N:\n",
    "        date = dt.datetime.strptime(k, '%Y-%m-%d').date() + dt.timedelta(days=1)\n",
    "    else:\n",
    "        date = df.loc[pred_idx,'Date']\n",
    "\n",
    "    std_avg_predictions.append(np.mean(train_data[pred_idx-window_size:pred_idx]))\n",
    "    mse_errors.append((std_avg_predictions[-1]-train_data[pred_idx])**2)\n",
    "    std_avg_x.append(date)\n",
    "\n",
    "print('MSE error for standard averaging: %.5f'%(0.5*np.mean(mse_errors)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72604573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# more accurate one-step prediction method.\n",
    "\n",
    "plt.figure(figsize = (18,9))\n",
    "plt.plot(range(df.shape[0]),all_mid_data,color='b',label='True')\n",
    "plt.plot(range(window_size,N),std_avg_predictions,color='orange',label='Prediction')\n",
    "#plt.xticks(range(0,df.shape[0],50),df['Date'].loc[::50],rotation=45)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Mid Price')\n",
    "plt.legend(fontsize=18)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b9c9d5",
   "metadata": {},
   "source": [
    "# Exponential Moving Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f10bf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 100\n",
    "N = train_data.size\n",
    "\n",
    "run_avg_predictions = []\n",
    "run_avg_x = []\n",
    "\n",
    "mse_errors = []\n",
    "\n",
    "running_mean = 0.0\n",
    "run_avg_predictions.append(running_mean)\n",
    "\n",
    "decay = 0.5\n",
    "\n",
    "for pred_idx in range(1,N):\n",
    "\n",
    "    running_mean = running_mean*decay + (1.0-decay)*train_data[pred_idx-1]\n",
    "    run_avg_predictions.append(running_mean)\n",
    "    mse_errors.append((run_avg_predictions[-1]-train_data[pred_idx])**2)\n",
    "    run_avg_x.append(date)\n",
    "\n",
    "print('MSE error for EMA averaging: %.5f'%(0.5*np.mean(mse_errors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f819fa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize = (18,9))\n",
    "plt.plot(range(df.shape[0]),all_mid_data,color='b',label='True')\n",
    "plt.plot(range(0,N),run_avg_predictions,color='orange', label='Prediction')\n",
    "#plt.xticks(range(0,df.shape[0],50),df['Date'].loc[::50],rotation=45)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Mid Price')\n",
    "plt.legend(fontsize=18)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
